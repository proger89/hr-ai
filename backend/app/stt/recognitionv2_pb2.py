# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: recognitionv2.proto
# Protobuf Python Version: 5.27.2
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    27,
    2,
    '',
    'recognitionv2.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import duration_pb2 as google_dot_protobuf_dot_duration__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x13recognitionv2.proto\x12\x1asmartspeech.recognition.v2\x1a\x1egoogle/protobuf/duration.proto\"y\n\x12RecognitionRequest\x12\x41\n\x07options\x18\x01 \x01(\x0b\x32..smartspeech.recognition.v2.RecognitionOptionsH\x00\x12\x15\n\x0b\x61udio_chunk\x18\x02 \x01(\x0cH\x00\x42\t\n\x07request\"\x9a\x02\n\x13RecognitionResponse\x12\x42\n\rtranscription\x18\x01 \x01(\x0b\x32).smartspeech.recognition.v2.TranscriptionH\x00\x12?\n\x0c\x62\x61\x63kend_info\x18\x02 \x01(\x0b\x32\'.smartspeech.recognition.v2.BackendInfoH\x00\x12<\n\x07insight\x18\x03 \x01(\x0b\x32).smartspeech.recognition.v2.InsightResultH\x00\x12\x34\n\x03vad\x18\x04 \x01(\x0b\x32%.smartspeech.recognition.v2.VADResultH\x00\x42\n\n\x08response\"\xd6\x03\n\rTranscription\x12\x0f\n\x07\x63hannel\x18\x01 \x01(\x05\x12\x37\n\x07results\x18\x02 \x03(\x0b\x32&.smartspeech.recognition.v2.Hypothesis\x12\x0b\n\x03\x65ou\x18\x03 \x01(\x08\x12\x39\n\neou_reason\x18\x04 \x01(\x0e\x32%.smartspeech.recognition.v2.EouReason\x12\x38\n\x15processed_audio_start\x18\x05 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x36\n\x13processed_audio_end\x18\x06 \x01(\x0b\x32\x19.google.protobuf.Duration\x12=\n\x0f\x65motions_result\x18\x07 \x01(\x0b\x32$.smartspeech.recognition.v2.Emotions\x12=\n\x0cspeaker_info\x18\x08 \x01(\x0b\x32\'.smartspeech.recognition.v2.SpeakerInfo\x12\x43\n\x0fperson_identity\x18\t \x01(\x0b\x32*.smartspeech.recognition.v2.PersonIdentity\"\'\n\rInsightResult\x12\x16\n\x0einsight_result\x18\n \x01(\t\"\x92\x01\n\tVADResult\x12\x0f\n\x07\x63hannel\x18\x01 \x01(\x05\x12\x37\n\x14processed_audio_time\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration\x12;\n\x18utterance_detection_time\x18\x03 \x01(\x0b\x32\x19.google.protobuf.Duration\"\x1e\n\x0cOptionalBool\x12\x0e\n\x06\x65nable\x18\x01 \x01(\x08\"\xb9\x08\n\x12RecognitionOptions\x12T\n\x0e\x61udio_encoding\x18\x01 \x01(\x0e\x32<.smartspeech.recognition.v2.RecognitionOptions.AudioEncoding\x12\x13\n\x0bsample_rate\x18\x02 \x01(\x05\x12\x16\n\x0e\x63hannels_count\x18\x03 \x01(\x05\x12\x10\n\x08language\x18\x04 \x01(\t\x12\r\n\x05model\x18\x05 \x01(\t\x12H\n\x16\x65nable_multi_utterance\x18\x06 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12H\n\x16\x65nable_partial_results\x18\x07 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12\x18\n\x10hypotheses_count\x18\x08 \x01(\x05\x12\x34\n\x11no_speech_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x35\n\x12max_speech_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x30\n\x05hints\x18\x0b \x01(\x0b\x32!.smartspeech.recognition.v2.Hints\x12X\n\x1aspeaker_separation_options\x18\x0c \x01(\x0b\x32\x34.smartspeech.recognition.v2.SpeakerSeparationOptions\x12O\n\x15normalization_options\x18\r \x01(\x0b\x32\x30.smartspeech.recognition.v2.NormalizationOptions\x12\x16\n\x0einsight_models\x18\x0e \x03(\t\x12<\n\nenable_vad\x18\x0f \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12H\n\x16\x63ustom_ws_flow_control\x18\x10 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12H\n\x16\x65nable_long_utterances\x18\x11 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12!\n\x19truncate_last_punctuation\x18\x12 \x03(\t\"z\n\rAudioEncoding\x12\x1e\n\x1a\x41UDIO_ENCODING_UNSPECIFIED\x10\x00\x12\r\n\tPCM_S16LE\x10\x01\x12\x08\n\x04OPUS\x10\x02\x12\x07\n\x03MP3\x10\x03\x12\x08\n\x04\x46LAC\x10\x04\x12\x08\n\x04\x41LAW\x10\x05\x12\t\n\x05MULAW\x10\x06\x12\x08\n\x04G729\x10\x07\"\x93\x03\n\x14NormalizationOptions\x12\x38\n\x06\x65nable\x18\x01 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12\x42\n\x10profanity_filter\x18\x02 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12=\n\x0bpunctuation\x18\x03 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12@\n\x0e\x63\x61pitalization\x18\x04 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12:\n\x08question\x18\x05 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\x12@\n\x0e\x66orce_cyrillic\x18\x06 \x01(\x0b\x32(.smartspeech.recognition.v2.OptionalBool\"^\n\x05Hints\x12\r\n\x05words\x18\x01 \x03(\t\x12\x16\n\x0e\x65nable_letters\x18\x02 \x01(\x08\x12.\n\x0b\x65ou_timeout\x18\x03 \x01(\x0b\x32\x19.google.protobuf.Duration\"[\n\x18SpeakerSeparationOptions\x12\x0e\n\x06\x65nable\x18\x01 \x01(\x08\x12 \n\x18\x65nable_only_main_speaker\x18\x02 \x01(\x08\x12\r\n\x05\x63ount\x18\x03 \x01(\x05\"\xc5\x02\n\nHypothesis\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x17\n\x0fnormalized_text\x18\x02 \x01(\t\x12(\n\x05start\x18\x03 \x01(\x0b\x32\x19.google.protobuf.Duration\x12&\n\x03\x65nd\x18\x04 \x01(\x0b\x32\x19.google.protobuf.Duration\x12M\n\x0fword_alignments\x18\x05 \x03(\x0b\x32\x34.smartspeech.recognition.v2.Hypothesis.WordAlignment\x1ao\n\rWordAlignment\x12\x0c\n\x04word\x18\x01 \x01(\t\x12(\n\x05start\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration\x12&\n\x03\x65nd\x18\x03 \x01(\x0b\x32\x19.google.protobuf.Duration\"\xb5\x01\n\x08\x45motions\x12\x10\n\x08positive\x18\x01 \x01(\x02\x12\x0f\n\x07neutral\x18\x02 \x01(\x02\x12\x10\n\x08negative\x18\x03 \x01(\x02\x12\x12\n\npositive_a\x18\x04 \x01(\x02\x12\x11\n\tneutral_a\x18\x05 \x01(\x02\x12\x12\n\nnegative_a\x18\x06 \x01(\x02\x12\x12\n\npositive_t\x18\x07 \x01(\x02\x12\x11\n\tneutral_t\x18\x08 \x01(\x02\x12\x12\n\nnegative_t\x18\t \x01(\x02\"P\n\x0b\x42\x61\x63kendInfo\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x15\n\rmodel_version\x18\x02 \x01(\t\x12\x16\n\x0eserver_version\x18\x03 \x01(\t\"B\n\x0bSpeakerInfo\x12\x12\n\nspeaker_id\x18\x01 \x01(\x05\x12\x1f\n\x17main_speaker_confidence\x18\x02 \x01(\x02\"\xa3\x01\n\x0ePersonIdentity\x12\x30\n\x03\x61ge\x18\x01 \x01(\x0e\x32#.smartspeech.recognition.v2.AgeType\x12\x36\n\x06gender\x18\x02 \x01(\x0e\x32&.smartspeech.recognition.v2.GenderType\x12\x11\n\tage_score\x18\x03 \x01(\x02\x12\x14\n\x0cgender_score\x18\x04 \x01(\x02*X\n\tEouReason\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x0b\n\x07ORGANIC\x10\x01\x12\x15\n\x11NO_SPEECH_TIMEOUT\x10\x02\x12\x16\n\x12MAX_SPEECH_TIMEOUT\x10\x03*-\n\x07\x41geType\x12\x0c\n\x08\x41GE_NONE\x10\x00\x12\t\n\x05\x43HILD\x10\x01\x12\t\n\x05\x41\x44ULT\x10\x02*3\n\nGenderType\x12\x0f\n\x0bGENDER_NONE\x10\x00\x12\x08\n\x04MALE\x10\x01\x12\n\n\x06\x46\x45MALE\x10\x02\x32\x7f\n\x0bSmartSpeech\x12p\n\tRecognize\x12..smartspeech.recognition.v2.RecognitionRequest\x1a/.smartspeech.recognition.v2.RecognitionResponse(\x01\x30\x01\x42\x13\n\x04TODOZ\x0b./;protocolb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'recognitionv2_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'\n\004TODOZ\013./;protocol'
  _globals['_EOUREASON']._serialized_start=3693
  _globals['_EOUREASON']._serialized_end=3781
  _globals['_AGETYPE']._serialized_start=3783
  _globals['_AGETYPE']._serialized_end=3828
  _globals['_GENDERTYPE']._serialized_start=3830
  _globals['_GENDERTYPE']._serialized_end=3881
  _globals['_RECOGNITIONREQUEST']._serialized_start=83
  _globals['_RECOGNITIONREQUEST']._serialized_end=204
  _globals['_RECOGNITIONRESPONSE']._serialized_start=207
  _globals['_RECOGNITIONRESPONSE']._serialized_end=489
  _globals['_TRANSCRIPTION']._serialized_start=492
  _globals['_TRANSCRIPTION']._serialized_end=962
  _globals['_INSIGHTRESULT']._serialized_start=964
  _globals['_INSIGHTRESULT']._serialized_end=1003
  _globals['_VADRESULT']._serialized_start=1006
  _globals['_VADRESULT']._serialized_end=1152
  _globals['_OPTIONALBOOL']._serialized_start=1154
  _globals['_OPTIONALBOOL']._serialized_end=1184
  _globals['_RECOGNITIONOPTIONS']._serialized_start=1187
  _globals['_RECOGNITIONOPTIONS']._serialized_end=2268
  _globals['_RECOGNITIONOPTIONS_AUDIOENCODING']._serialized_start=2146
  _globals['_RECOGNITIONOPTIONS_AUDIOENCODING']._serialized_end=2268
  _globals['_NORMALIZATIONOPTIONS']._serialized_start=2271
  _globals['_NORMALIZATIONOPTIONS']._serialized_end=2674
  _globals['_HINTS']._serialized_start=2676
  _globals['_HINTS']._serialized_end=2770
  _globals['_SPEAKERSEPARATIONOPTIONS']._serialized_start=2772
  _globals['_SPEAKERSEPARATIONOPTIONS']._serialized_end=2863
  _globals['_HYPOTHESIS']._serialized_start=2866
  _globals['_HYPOTHESIS']._serialized_end=3191
  _globals['_HYPOTHESIS_WORDALIGNMENT']._serialized_start=3080
  _globals['_HYPOTHESIS_WORDALIGNMENT']._serialized_end=3191
  _globals['_EMOTIONS']._serialized_start=3194
  _globals['_EMOTIONS']._serialized_end=3375
  _globals['_BACKENDINFO']._serialized_start=3377
  _globals['_BACKENDINFO']._serialized_end=3457
  _globals['_SPEAKERINFO']._serialized_start=3459
  _globals['_SPEAKERINFO']._serialized_end=3525
  _globals['_PERSONIDENTITY']._serialized_start=3528
  _globals['_PERSONIDENTITY']._serialized_end=3691
  _globals['_SMARTSPEECH']._serialized_start=3883
  _globals['_SMARTSPEECH']._serialized_end=4010
# @@protoc_insertion_point(module_scope)
